# -*- coding: utf-8 -*-
"""LSTM-PhanLoaiCamXuc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13mbjRYVWlc_zoUpJ-JK5KSIHZhEMY9xh
"""

import numpy as np
import os

#lấy danh sách file
dir_train_neg = os.listdir('./data/data_train/train/neg/')
dir_train_pos = os.listdir('./data/data_train/train/pos/')
dir_test_neg = os.listdir('./data/data_train/test/neg/')
dir_test_pos = os.listdir('./data/data_train/test/pos/')

#khởi tạo data
data_test, data_train = [],[]
label_test, label_train = [],[]
train = []
test = []

#Lấy dữ liệu đưa vào data đã khởi tạo
for i in dir_train_neg:
  f1 = open('./data/data_train/train/neg/'+i,mode='r',encoding='UTF-8')
  d = f1.read()
  train.append([d,0])
  f1.close()
for i in dir_train_pos:
  f1 = open('./data/data_train/train/pos/'+i,mode='r',encoding='UTF-8')
  d = f1.read()
  train.append([d,1])
  f1.close()
for i in dir_test_neg:
  f1 = open('./data/data_train/test/neg/'+i,mode='r',encoding='UTF-8')
  d = f1.read()
  test.append([d,0])
  f1.close()
for i in dir_test_pos:
  f1 = open('./data/data_train/test/pos/'+i,mode='r',encoding='UTF-8')
  d = f1.read()
  test.append([d,1])
  f1.close()

#Xáo trộn dữ liệu
train = np.array(train)
test = np.array(test)

np.random.shuffle(train)
np.random.shuffle(test)

#Lấy các câu + nhãn cho train và test
data_train = train[:,0]
data_test = test[:,0]

label_train=train[:,1]
label_test=test[:,1]

vocab_size = 15000
embedding_dim = 64
max_length = 140

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>")
tokenizer.fit_on_texts(data_test+data_train)

data_train = tokenizer.texts_to_sequences(data_train)
padded_train_sequences = pad_sequences(data_train, maxlen=max_length, truncating='post', padding="post")

data_test = tokenizer.texts_to_sequences(data_test)
padded_test_sequences = pad_sequences(data_test, maxlen=max_length, truncating='post', padding="post")

padded_train_sequences

padded_train_sequences.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense

model = Sequential()

model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))

model.add(LSTM(32))

model.add(Dense(16, activation='relu'))

model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])

model.summary()

model.fit(padded_train_sequences, label_train, epochs=10, validation_data=(padded_test_sequences, label_test))

test_sen = ["Đồ ăn rất ngon, tôi sẽ ghé lần nữa"]

test_seq = tokenizer.texts_to_sequences(test_sen)

padded_test_seq = pad_sequences(test_seq, maxlen=max_length, truncating="post", padding="post")

padded_test_seq

model.predict(padded_test_seq)